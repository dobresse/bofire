{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fitting and hyperopt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and general Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/bofire/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bofire.benchmarks.api import Himmelblau, hyperoptimize\n",
    "from bofire.data_models.surrogates.api import SingleTaskGPSurrogate\n",
    "import bofire.surrogates.api as surrogates \n",
    "from bofire.surrogates.feature_importance import permutation_importance_hook, combine_permutation_importances\n",
    "from bofire.plot.feature_importance import plot_feature_importance_by_feature_plotly\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "from bofire.surrogates.diagnostics import CvResults2CrossValidationValues, CrossValidationValues\n",
    "from bofire.data_models.enum import RegressionMetricsEnum\n",
    "import random\n",
    "import json\n",
    "\n",
    "benchmark = Himmelblau()\n",
    "experiments = benchmark.f(benchmark.domain.inputs.sample(25), return_complete=True)\n",
    "\n",
    "surrogate_data = SingleTaskGPSurrogate(inputs=benchmark.domain.inputs, outputs=benchmark.domain.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestMethod(BaseModel):\n",
    "    type: str\n",
    "\n",
    "class CrossValidation(TestMethod):\n",
    "    type: Literal[\"CrossValidation\"] = \"CrossValidation\"\n",
    "    foldCount: int"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS = 5\n",
    "RANDOM_STATE = random.randint(1,1000)\n",
    "\n",
    "# remove all non valid output data for cross val\n",
    "cleaned_experiments = surrogate_data.outputs.preprocess_experiments_all_valid_outputs(experiments=experiments)\n",
    "# generate the optimized surrogate data\n",
    "opt_surrogate_data, metrics = hyperoptimize(surrogate_data=surrogate_data, training_data=cleaned_experiments, folds=FOLDS, random_state=RANDOM_STATE)\n",
    "metrics = metrics.reset_index(drop=True)\n",
    "# calculate the metrics for optimized surrogate data, this is needed if we have more sophisticated splitting schemes in the future\n",
    "surrogate = surrogates.map(opt_surrogate_data)\n",
    "cv_train, cv_test, pi = surrogate.cross_validate(cleaned_experiments, folds=FOLDS, hooks={\"pemutation_imprtance\": permutation_importance_hook}, random_state=RANDOM_STATE)\n",
    "testMethod = CrossValidation(foldCount=FOLDS)\n",
    "cvResultsTrain = CvResults2CrossValidationValues(cv_train)\n",
    "cvResultsTest = CvResults2CrossValidationValues(cv_test)\n",
    "metricsTrain = {surrogate.outputs[0].key: cv_train.get_metrics(combine_folds=False).describe().loc[\"mean\"].to_dict()}\n",
    "metricsTest = {surrogate.outputs[0].key: cv_test.get_metrics(combine_folds=True).describe().loc[\"mean\"].to_dict()}\n",
    "# train to the whole dataset and save the model\n",
    "surrogate.fit(experiments=experiments)\n",
    "# get the dump\n",
    "dump = surrogate.dumps()\n",
    "# create the misc field\n",
    "misc = {\n",
    "    \"hyperparameter_optimization\": {\n",
    "        \"domain\": surrogate_data.hyperconfig.domain.json(),\n",
    "        \"metrics\": json.dumps(metrics.to_dict()),\n",
    "    },\n",
    "    \"feature_importance\": {\n",
    "        \"permutation_feature_importance\":  json.dumps({m.name: combine_permutation_importances(pi[\"pemutation_imprtance\"], m).describe().loc[[\"mean\", \"std\"]].to_dict() for m in RegressionMetricsEnum})\n",
    "    }\n",
    "}\n",
    "# save to backend\n",
    "# - opt_surrogate_data\n",
    "# - dump\n",
    "# - testMethod\n",
    "# - cvResultsTrain\n",
    "# - cvResultsTest\n",
    "# - metricsTrain\n",
    "# - metricsTest\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS = 5\n",
    "RANDOM_STATE = random.randint(1,1000)\n",
    "\n",
    "cleaned_experiments = surrogate_data.outputs.preprocess_experiments_all_valid_outputs(experiments=experiments)\n",
    "# calculate the metrics for optimized surrogate data, this is needed if we have more sophisticated splitting schemes in the future\n",
    "surrogate = surrogates.map(surrogate_data)\n",
    "cv_train, cv_test, pi = surrogate.cross_validate(cleaned_experiments, folds=FOLDS, hooks={\"pemutation_imprtance\": permutation_importance_hook}, random_state=RANDOM_STATE)\n",
    "testMethod = CrossValidation(foldCount=FOLDS)\n",
    "cvResultsTrain = CvResults2CrossValidationValues(cv_train)\n",
    "cvResultsTest = CvResults2CrossValidationValues(cv_test)\n",
    "metricsTrain = {surrogate.outputs[0].key: cv_train.get_metrics(combine_folds=False).describe().loc[\"mean\"].to_dict()}\n",
    "metricsTest = {surrogate.outputs[0].key: cv_test.get_metrics(combine_folds=True).describe().loc[\"mean\"].to_dict()}\n",
    "# train to the whole dataset and save the model\n",
    "surrogate.fit(experiments=experiments)\n",
    "# get the dump\n",
    "dump = surrogate.dumps()\n",
    "# create the misc field\n",
    "misc = {\n",
    "    \"feature_importance\": {\n",
    "        \"permutation_feature_importance\":  json.dumps({m.name: combine_permutation_importances(pi[\"pemutation_imprtance\"], m).describe().loc[[\"mean\", \"std\"]].to_dict() for m in RegressionMetricsEnum})\n",
    "    }\n",
    "}\n",
    "# save to backend\n",
    "# - surrogate_data\n",
    "# - dump\n",
    "# - testMethod\n",
    "# - cvResultsTrain\n",
    "# - cvResultsTest\n",
    "# - metricsTrain\n",
    "# - metricsTest\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPEROPTIMIZE = False\n",
    "FOLDS = 5\n",
    "RANDOM_STATE = random.randint(1,1000)\n",
    "\n",
    "# remove all non valid output data for cross val\n",
    "cleaned_experiments = surrogate_data.outputs.preprocess_experiments_all_valid_outputs(experiments=experiments)\n",
    "# generate the optimized surrogate data\n",
    "if HYPEROPTIMIZE:\n",
    "    opt_surrogate_data, metrics = hyperoptimize(surrogate_data=surrogate_data, training_data=cleaned_experiments, folds=FOLDS, random_state=RANDOM_STATE)\n",
    "    metrics = metrics.reset_index(drop=True)\n",
    "else:\n",
    "    opt_surrogate_data = surrogate_data\n",
    "# calculate the metrics for optimized surrogate data, this is needed if we have more sophisticated splitting schemes in the future\n",
    "surrogate = surrogates.map(opt_surrogate_data)\n",
    "cv_train, cv_test, pi = surrogate.cross_validate(cleaned_experiments, folds=FOLDS, hooks={\"pemutation_imprtance\": permutation_importance_hook}, random_state=RANDOM_STATE)\n",
    "testMethod = CrossValidation(foldCount=FOLDS)\n",
    "cvResultsTrain = CvResults2CrossValidationValues(cv_train)\n",
    "cvResultsTest = CvResults2CrossValidationValues(cv_test)\n",
    "metricsTrain = {surrogate.outputs[0].key: cv_train.get_metrics(combine_folds=False).describe().loc[\"mean\"].to_dict()}\n",
    "metricsTest = {surrogate.outputs[0].key: cv_test.get_metrics(combine_folds=True).describe().loc[\"mean\"].to_dict()}\n",
    "# train to the whole dataset and save the model\n",
    "surrogate.fit(experiments=experiments)\n",
    "# get the dump\n",
    "dump = surrogate.dumps()\n",
    "# create the misc field\n",
    "misc = {\"feature_importance\": {\n",
    "        \"permutation_feature_importance\":  json.dumps({m.name: combine_permutation_importances(pi[\"pemutation_imprtance\"], m).describe().loc[[\"mean\", \"std\"]].to_dict() for m in RegressionMetricsEnum})\n",
    "    }}\n",
    "if HYPEROPTIMIZE:\n",
    "    misc[\"hyperparameter_optimization\"] = {\n",
    "        \"domain\": surrogate_data.hyperconfig.domain.json(),\n",
    "        \"metrics\": json.dumps(metrics.to_dict()),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bofire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
